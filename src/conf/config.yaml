# defaults
defaults:
    - model: bandsplitmodel
    - train_dataset: mixing_dataset
    - val_dataset: mixing_dataset
    - test_dataset: default
    - sad: default
    - augmentations: noaug
    - featurizer: stft
    - callbacks: default
    - _self_

# data
train_loader:
    batch_size: 5
    num_workers: 16
    shuffle: True
    drop_last: True
val_loader:
    batch_size: 5
    num_workers: 16
    shuffle: False
    drop_last: False

# optimization
opt:
    _target_: torch.optim.AdamW
    lr: 0.0005

ckpt_path: null

logger:
    _target_: pytorch_lightning.loggers.TensorBoardLogger
    save_dir: "/tb_logs"
    name: ""
    version: ""
    default_hp_metric: False

trainer:
    _target_: pytorch_lightning.trainer.Trainer
    fast_dev_run: False
    max_epochs: 2000
    check_val_every_n_epoch: 1
    num_sanity_val_steps: 0
    log_every_n_steps: 100
    accelerator: gpu
    devices: "0, 1"
    strategy:
        _target_: pytorch_lightning.strategies.ddp.DDPStrategy
        find_unused_parameters: True
    gradient_clip_val: 3
    accumulate_grad_batches: 6
    precision: bf16
    enable_progress_bar: True
    benchmark: True
    deterministic: False

# hydra
experiment_dirname: "test"
hydra:
    run:
        dir: logs/${...experiment_dirname}/${train_dataset.target[0]}/${now:%Y-%m-%d}_${now:%H-%M}
    job:
        chdir: False

model_type: bandsplitmodel

# Losses
complex_error: False
phase_loss: False
mag_loss: False
time_loss: True
multi_stft_loss: True
consistency: False

