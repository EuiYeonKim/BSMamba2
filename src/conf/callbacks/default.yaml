lr_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: "epoch"

model_ckpt:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "val/loss"
    mode: "min"
    save_top_k: 4
    dirpath: "/weights"
    filename: "epoch{epoch:02d}-val_loss{val/loss:.2f}"
    auto_insert_metric_name: False
    save_last: True

model_ckpt_usdr:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "val/usdr"
    mode: "max"
    save_top_k: 4
    dirpath: ${..model_ckpt.dirpath}
    filename: "epoch{epoch:02d}-val_usdr{val/usdr:.2f}"
    auto_insert_metric_name: False

ema:
    _target_: utils.callbacks.EMA
    decay: 0.999
    validate_original_weights: False
    every_n_steps: 1
